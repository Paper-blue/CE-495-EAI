# CE 495 EAI 项目演示演讲稿
## 总时长：7分钟

---

## 第1页：标题页（10秒）
**时间：0:00-0:10**

大家好，我是[您的姓名]，今天我将为大家展示我们团队在CE 495能量感知智能课程中的期末项目成果。我们的研究题目是"面向能量感知的AI部署：模型量化与硬件平台相互作用的研究"。这是我们团队三人合作完成的项目，分别专注于量化技术、硬件评估和能量指标。

---

## 第2页：研究动机（25秒）
**时间：0:10-0:35**

首先让我们看一下研究动机。训练一个大型Transformer模型需要消耗约**128万千瓦时**的电力，这相当于多辆汽车终身的碳排放。虽然训练阶段的能耗问题已经得到广泛关注，但在实际部署场景中，推理阶段的能量优化却没有得到足够重视。如右图所示，推理阶段的能耗虽然单次较低，但考虑到大规模部署的累积效应，其总体能耗同样不可忽视。这就是我们研究的出发点——**推理阶段的能量优化在部署场景中具有关键重要性**。

---

## 第3页：核心研究问题（25秒）  
**时间：0:35-1:00**

我们的核心研究问题是：**如何通过量化技术和硬件平台的系统优化实现能量高效的LLM部署？**

现有研究存在三个主要局限：首先，大多数研究关注孤立的优化因素；其次，缺乏系统的评估框架；第三，缺少实用的部署指导。

我们的贡献包括：系统的协同优化方法、全面的评估框架，以及实用的部署指南。我们将展示如何通过系统化的方法，在保持模型性能的同时显著降低能耗。

---

## 第4页：方法论概述（30秒）
**时间：1:00-1:30**

我们采用了三支柱研究方法。

**第一支柱是量化分析**：我们评估了INT8、FP16和动态量化三种技术，分析了性能-能耗权衡和内存优化效果。

**第二支柱是硬件评估**：我们测试了6个GPU平台，涵盖3代硬件架构，进行了全面的能耗分析。

**第三支柱是能量指标**：我们开发了新颖的EOR和TWEOR指标，实现1Hz精度监测，优化部署决策。

这形成了一个**系统化的协同优化框架：6个平台 × 6个模型 × 5个任务**的全面评估体系。

---

## 第5页：新型能量效率指标（30秒）
**时间：1:30-2:00**

我们开发了两个关键的能量效率指标。

**EOR（能量输出比）**定义为性能分数除以能耗，以瓦时为单位。这个指标能够直接反映每单位能耗所获得的模型性能。

**TWEOR（时间加权能量输出比）**进一步将推理时间纳入考虑，提供更全面的效率评估。

这些指标的优势在于：能够捕捉复杂的权衡关系，整合时间效率，并支持部署优化决策。我们使用NVIDIA SMI以1Hz采样率进行精确的能量测量，确保数据的准确性和可靠性。

---

## 第6页：实验配置（30秒）
**时间：2:00-2:30**

我们的实验配置非常全面。

在硬件方面，我们测试了6个GPU平台：A100、RTX 4090、3090Ti、4060Ti、V100和L40S。在模型方面，我们选择了6个代表性的语言模型：Qwen2.5、DeepSeek-R1、Mistral、Neural-Chat、Bloomz和Yi。量化方面，我们测试了INT8、FP16和动态量化三种策略。

基准测试包括5个重要任务：MMLU多任务语言理解、HellaSwag常识推理、ARC科学问答、TruthfulQA真实性评估，以及GSM8K数学推理。

这构成了**6个平台 × 6个模型 × 5个基准任务**的全面评估体系。

---

## 第7页：发现1 - 量化技术效果（60秒）
**时间：2:30-3:30**

现在让我们看第一个重要发现：量化技术的效果。

从表格可以看到，**INT8量化**表现最优，实现了**25%的能耗降低**，准确度损失小于1%，EOR提升达到**32.1%**，评级为优秀。FP16混合精度实现16.3%的能耗降低，准确度损失仅0.2%，评级良好。动态量化的效果相对温和，能耗降低10.5%。

具体以DeepSeek-7B模型为例，INT8量化将能耗从**39.65瓦时降低到29.74瓦时**，准确度降低仅0.7-0.9个百分点。这得益于减少的内存带宽需求和现代GPU对整数运算的优化。

右侧图表显示了量化技术的权衡关系，INT8量化在能耗和性能之间找到了最佳平衡点。这证明了INT8量化是最具实用价值的量化策略。

---

## 第8页：发现2a - A100领先地位（30秒）
**时间：3:30-4:00**

第二个发现关于硬件平台。**A100 PCIE显然是能量效率的冠军**。

A100的技术规格包括1,555 GB/s的内存带宽、第三代Tensor Cores、40GB HBM2内存，以及先进的Ampere架构。

在性能表现上，A100在所有场景下都实现了**最高的能量效率**，针对AI工作负载进行了优化，具有卓越的内存带宽利用率和企业级可靠性。

最重要的是，A100在所有基准测试任务中都**在EOR和TWEOR指标上保持领先地位**，这证明了其在能量效率方面的绝对优势。

---

## 第9页：发现2b - 平台分析（30秒）
**时间：4:00-4:30**

进一步的平台分析显示，我们可以将GPU平台分为三个类别：**高带宽平台**如A100和V100、**功耗优化平台**如RTX 4060Ti，以及**高性能平台**如RTX 4090。

值得注意的是，**Ada Lovelace架构**相比前代实现了**20-30%的能量效率提升**，这体现了硬件架构演进对能效的重要影响。

右侧的性能热图直观地展示了不同平台在各项指标上的表现，A100在大部分指标上都显示出最深的颜色，表明其优越的性能。

---

## 第10页：发现3 - 协同优化效果（60秒）
**时间：4:30-5:30**

第三个也是最重要的发现是协同优化效果。**A100 PCIE与INT8量化的组合实现了40%的整体能量效率提升**。

从表格可以看到，A100+INT8组合的效率提升达到**40.0%**，RTX 4090+FP16组合达到**35.2%**，RTX 4060Ti+动态量化组合达到25.1%。

除了硬件-软件协同优化，我们还发现**知识蒸馏技术**能够额外提供**19.8%的能耗降低**，同时保持**98%以上的准确度**。

这个发现的关键意义在于：**硬件-软件协同优化能够实现乘法效应的收益**。单独使用量化或单独使用高效硬件的效果是有限的，但将两者结合起来，能够实现超越简单加法的协同效应。

---

## 第11页：部署决策流程（30秒）
**时间：5:30-6:00**

基于我们的研究结果，我们设计了一个系统化的部署决策流程。

决策流程从**部署需求评估**开始，首先确定可用的硬件资源。如果有A100可用，则需要考虑对准确度的需求：**高精度需求选择A100+FP16，能效优先选择A100+INT8**。

如果使用RTX系列GPU，则需要考虑能耗优先级：**性能优先选择RTX 4090+FP16，能效优先选择RTX 4060Ti+动态量化**。

这个决策流程遵循**评估→分析→考虑→优化**的系统化过程，确保在不同场景下都能找到最优的配置方案。

---

## 第12页：部署决策矩阵（30秒）
**时间：6:00-6:30**

我们进一步将决策流程具体化为部署决策矩阵。

针对不同使用场景，我们提供了具体的推荐配置：

**数据中心生产环境**：A100 PCIE + INT8量化，性能保持98%，效率提升**40%**，成本较高但收益最大。

**企业应用**：RTX 4090 + FP16，性能保持99%，效率提升**35%**，成本适中。

**边缘计算部署**：RTX 4060Ti + 动态量化，性能95%，效率提升25%，成本最低。

选择原则是：**精度优先选择FP16混合精度，能效优先选择INT8量化，灵活性优先选择动态量化**。这个矩阵为实际部署提供了明确的指导。

---

## 第13页：应用指导方案（30秒）
**时间：6:30-7:00**

最后，我们为三种典型部署场景提供了具体的应用指导方案。

**数据中心生产**：使用A100 PCIE + INT8量化，适用于高吞吐量、受控环境，性能98%，效率提升**40%**。

**企业应用**：使用RTX 4090 + FP16混合精度，平衡成本与性能，性能99%，效率提升**35%**。

**边缘计算部署**：使用RTX 4060 Ti + 动态量化，适应功耗限制和紧凑空间，性能95%，效率提升**25%**。

这些**针对不同部署场景和运营需求的定制化推荐**，为实际应用提供了直接可用的指导方案。

---

## 第14页：研究贡献与影响（30秒）
**时间：7:00-7:30**

总结我们的关键贡献：首先是量化-硬件协同优化框架，其次是新颖的EOR/TWEOR能量效率指标，第三是基于证据的部署指南。

我们的**关键结果**包括：**25%的能耗降低**、**40%的协同优化收益**，以及**98%以上的准确度保持**。

这项研究为能量感知的AI部署提供了系统化的解决方案，对推动绿色AI技术发展具有重要意义。

**谢谢大家的聆听！**

---

## 演讲要点总结

### 时间分配：
- 开场介绍：1分钟（幻灯片1-3）
- 方法论：1.5分钟（幻灯片4-6）
- 研究发现：3分钟（幻灯片7-10）
- 应用指导：1分钟（幻灯片11-13）
- 总结：0.5分钟（幻灯片14）

### 关键数据强调：
- **1,287,000 kWh** - 大模型训练能耗
- **25%** - INT8量化能耗降低
- **40%** - 协同优化效率提升  
- **98%+** - 准确度保持

### 演讲技巧：
1. 语速控制在每分钟150-170字
2. 在关键数据前稍作停顿，增强效果
3. 使用手势指向相关图表
4. 保持自信的语调和适当的停顿
5. 在重要发现处加重语气 