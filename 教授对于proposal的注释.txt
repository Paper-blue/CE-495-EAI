If I understood the proposal correctly, the plan is essentially to benchmark (or analyze benchmarks you've previously done) the efficiency of AI models on embedded and more power GPU platforms. Please make sure to mention how this work differs from other similar studies, and a lot of the results and insights will come from the analysis, which I'm interested to see the findings of. I know you won't be able to run every single model out there, but I assume you could pick some representative architectures and comment on broader generalizations and trends beyond just the models you could run. Other than that looking forward to reading your work!